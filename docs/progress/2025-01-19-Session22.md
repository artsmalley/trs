# Session 22: Citation Fix - FileId Matching Solution (2025-01-19)

## What We Accomplished âœ…

### 1. UI Polish: Query Input Text Wrapping âœ…
**Issue**: Long queries scrolled horizontally off-screen in Query Corpus and Search Web tabs

**Fix**: Changed `Input` component to `Textarea`
- Added `rows={3}` for better visibility
- Added `resize-none` class
- Maintained Enter-to-submit behavior (Shift+Enter for new lines)

**Files modified**:
- `components/agents/browse-query-agent.tsx`
- `components/agents/web-search-agent.tsx`

**Result**: Long queries now wrap within visible area âœ…

---

### 2. Citation Investigation & Root Cause Analysis ğŸ”

**Problem Reported**: Citations that were working before (Session 12) stopped working

**User quote**: "We had the names displaying before somehow"

**Investigation Process**:
1. Added 6 DEBUG checkpoints to trace citation pipeline
2. Discovered filename matching was failing
3. Analyzed grounding chunk structure
4. Traced timeline back to Session 13 regression

**Root Cause Identified**:

#### Session 12 (Nov 14 AM): Citations Working âœ…
- Chunk titles: `upload-{timestamp}-{filename}.pdf`
- Example: `upload-1763123009682-Yoshino1985.pdf`
- Filename parsing extracted original filename â†’ matched to documents â†’ citations worked

#### Session 13 (Nov 14 PM): REGRESSION âŒ
- **Problem**: Japanese characters in filenames caused ByteString errors in Google SDK
- **Solution**: Strip filename from temp file to avoid Unicode issues
  ```typescript
  // Changed from: upload-{timestamp}-{filename}.pdf
  // To: upload-{timestamp}.pdf
  ```
- **Unintended consequence**: Broke citation extraction for ALL 241 subsequently uploaded documents
- **Why**: Chunk titles no longer contained original filenames â†’ matching logic failed

#### Session 22 (Jan 19): Investigation & Fix
- User noticed citations missing
- DEBUG output showed:
  ```
  [DEBUG 3] Match: upload-1763588882831.pdf â†’ upload-1763588882831.pdf â†’ false
  [DEBUG 4] docMap size: 0
  ```
- No way to match chunk titles to original documents using filename alone

---

### 3. The Solution: FileId Matching âœ…

**Discovery**: Redis metadata `fileId` field contains chunk title!

**Data correlation found**:
```
Chunk title (from Gemini grounding metadata):
  "upload-1763588882831.pdf"

Document fileId (in Redis):
  "fileSearchStores/toyotaresearchsystem-b8v65yx9esml/upload/operations/upload1763588882831pdf-0wvmirtphxwz"
```

**Key insight**: The fileId contains `upload1763588882831pdf` (normalized version of chunk title)

**Implementation**:
```typescript
// Normalize chunk title: remove dashes and dots
const normalizedTitle = chunkTitle.replace(/-/g, '').replace(/\./g, '');
// "upload-1763588882831.pdf" â†’ "upload1763588882831pdf"

// Find document by checking if fileId contains normalized title
const matchedDoc = approvedDocs.find(doc => {
  return doc.fileId && doc.fileId.includes(normalizedTitle);
});
```

**File modified**: `app/api/summary/route.ts` (lines 220-229)

**Result**:
- âœ… All 241 existing documents now have citation extraction working
- âœ… No re-upload needed
- âœ… Basic citations working: `[Yoshino1985, p.1, 2, 3]`

---

### 4. Code Cleanup âœ…

**Removed DEBUG statements** from:
- `app/api/summary/route.ts` (DEBUG 1, 2, 2.5, 3, 4, 6)
- `lib/inject-citations.ts` (DEBUG 5)

**Updated documentation**:
- `citation.md` - Added Session 22 Resolution section with full timeline and analysis
- `CLAUDE.md` - Added Google File Search Store limitations to Known Issues
- `docs/progress/2025-01-19-Session22.md` - Created this session log

---

## Files Modified

**Code changes**:
1. `components/agents/browse-query-agent.tsx` - UI: Input â†’ Textarea
2. `components/agents/web-search-agent.tsx` - UI: Input â†’ Textarea
3. `app/api/summary/route.ts` - FileId matching + DEBUG cleanup
4. `lib/inject-citations.ts` - DEBUG cleanup

**Documentation**:
5. `citation.md` - Session 22 Resolution section
6. `CLAUDE.md` - Known Issues: File Search Store limitations
7. `docs/progress/2025-01-19-Session22.md` - NEW: This file
8. `Next_steps.md` - Updated status (pending)

---

## Technical Details

### Citation Extraction Flow (Post-Fix)

1. **Query Gemini** with File Search tool
2. **Receive grounding chunks** with titles like `upload-1763588882831.pdf`
3. **Normalize chunk title**: Remove dashes and dots â†’ `upload1763588882831pdf`
4. **Match to document**: Find doc where `fileId.includes(normalizedTitle)`
5. **Extract citation info**: Get `citationKey` and page numbers from matched document
6. **Build docMap**: Aggregate citations from all chunks
7. **Inject citations**: Add citation markers at end of response text
8. **Return**: Annotated response + separate citations array

### Why This Works

**Session 13's Unicode fix** removed filenames from chunk titles but Google's File Search Store still includes them in the fileId path:
- Temp file created: `upload-1763588882831.pdf`
- Uploaded to File Search Store: Gets fileId like `fileSearchStores/.../upload1763588882831pdf-randomId`
- Redis stores this fileId in document metadata
- We can correlate chunk title â†’ fileId â†’ document

### Limitations

**Fragile matching**:
- Depends on Google's fileId format staying consistent
- String parsing instead of clean foreign key relationships
- No control over chunk metadata structure

**Why Supabase would be better**:
- Direct foreign keys: `chunk.document_id â†’ document.id`
- Explicit metadata: Store `citation_key` directly in chunk table
- No string parsing needed
- Better debugging and transparency

---

## Results

âœ… **Citations restored** for all 241 existing documents
âœ… **Format working**: `[Yoshino1985, p.1, 2, 3, 4]` or `[History2012; Yoshino1985, p.1-14]`
âœ… **No re-upload needed** - Works with existing corpus
âœ… **User satisfied**: "Ok this works as a temporary countermeasure"

---

## Next Steps

**Short-term (this week)**:
- Continue using current fileId matching solution
- Focus on content work, not infrastructure

**Long-term (next week+)**:
- Plan Supabase migration for better control
- User has existing Supabase account ($25/month)
- Migration effort: ~4-6 hours
- Benefits: Clean architecture, no vendor lock-in, better debugging

---

## Lessons Learned

1. **Regressions happen**: Session 13's Unicode fix had unintended consequences that went unnoticed for weeks
2. **Google File Search Store is opaque**: Limited control over chunk metadata makes debugging hard
3. **Workarounds are fragile**: FileId string matching works but depends on Google's implementation details
4. **User context is valuable**: "We had the names displaying before" led to discovery of Session 13 regression
5. **Managed services trade-off**: File Search Store handles chunking automatically but gives up control
6. **Custom RAG would be better**: Pinecone/Supabase would provide direct foreign keys and full metadata control

---

## User Feedback

> "Ok this works as a temporary countermeasure"

**Interpretation**:
- âœ… Citations working now - immediate need met
- â¸ï¸ Supabase migration deferred to next week (user has other priorities this week)
- ğŸ¯ User wants time to reflect and plan the migration properly

---

**End of Session 22** - 2025-01-19
