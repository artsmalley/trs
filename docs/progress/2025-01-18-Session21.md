# Session 21: Two-Tab Architecture - Query Corpus + Search Web (2025-01-18)

## What We Accomplished ✅

### 1. Fixed Reject Button Bug
**Issue**: Reject button failed to delete documents from File Search Store
- Only removed Redis metadata, leaving orphaned files in File Search Store
- Root cause: Delete endpoint checked for `files/` prefix but File Search Store uses `corpora/` prefix

**Fix**: Updated `/app/api/corpus/delete/route.ts`
- Imported `deleteDocumentFromStore` from file-search-store library
- Added logic to detect both File Search Store (`corpora/`) and Files API (`files/`) documents
- Proper deletion from all 3 layers: Blob + File Search Store + Redis

**Result**: Reject button now works correctly ✅

### 2. Fixed Follow-up Query Bug
**Issue**: Follow-up questions returned HTTP 400 error
- First query worked fine, second query failed
- Error: "Message content at index {i} too long (max 1000 characters)"

**Root Cause**: History validation limited ALL messages to 1000 characters
- Assistant responses often exceed 1000 chars (detailed 4-6 paragraph answers)
- When sent back as history, validation rejected them

**Fix**: Removed content length validation for history messages in `/lib/sanitize.ts`
- User messages already validated when first sent
- Assistant messages are AI-generated (trusted)
- History essential for conversation context
- Still protected by 50-message limit

**Result**: Follow-up queries now work correctly ✅

### 3. Implemented Two-Tab Architecture ✅

**User Request**: "I want to trace information from external sources too, not just corpus"

**Journey to Solution**:

**Approach 1: Dual Tools (FAILED)**
- Attempted to use both `fileSearch` + `googleSearch` tools together
- Result: API error `"Search as a tool and file search tool are not supported together"`
- Google API limitation: These tools are mutually exclusive

**Approach 2: Sequential Queries (EXECUTED BUT REVEALED PROBLEM)**
- Query 1: File Search (corpus) ✅ Returned specific facts with dates
- Query 2: Google Search (web) ✅ Executed but returned generic "Lean 101" knowledge
- Problem: Query 2 returned 0 tokens because model received full corpus context (47,754 tokens)

**User Insight**: "The google search of the internet will always return the perceived common answer but not the best facts and details. The system got 'swamped' with the generic internet responses."

**Approach 3: Separate Tabs (FINAL SOLUTION)**
- Realized combining results masks the knowledge gap
- User wants to SEE the difference between corpus (authoritative) and web (generic)
- Created two independent tabs:
  - **Query Corpus**: Strict citations, corpus-only responses
  - **Search Web**: Google Search, generic web knowledge

### 4. Simplified UI to Remove Constraints ✅

**Problem Discovered**: Mode/Length/Custom Instructions were interfering with citations
- User: "I think the way I set up the Query Corpus U/I is also part of the problem. By forcing modes and length this probably chokes the responses."
- Mode/Length instructions in system prompt were overriding strict citation requirements

**Solution**: Removed all UI constraints from both tabs
- Removed Mode dropdown (Standard, Find Examples, etc.)
- Removed Length dropdown (Brief, Medium, Detailed)
- Removed Custom Instructions collapsible textarea
- User now has full control through detailed prompts
- Burden of quality is on the user (acceptable for solo use)

### 5. Enforced Strict Citations ✅

**Problem**: Corpus queries weren't citing sources properly
- User: "Since it did not cite anything where did it get the information from? Is it still pulling from its training data?"

**Solution**: Added CRITICAL instructions at top of system prompt
- "You MUST ONLY use information retrieved by the File Search tool from the corpus documents"
- "You MUST cite EVERY factual claim using the Citation Key format: [CitationKey, p.#]"
- "DO NOT use your training data or general knowledge - ONLY use corpus documents"
- "Every sentence with factual information MUST include at least one citation"

**Result**: Corpus queries now return full citations like `[cite: History2012, 特殊鋼の研究・開発と鍛造技術の研究, p.1]`

### 6. Fixed Duplicate List Bug ✅

**Problem**: Both corpus and web queries generated TWO nearly identical lists

**Solution**: Added anti-duplication instruction
- "CRITICAL: Provide ONE clear, concise response. Do NOT repeat information, create multiple lists, or generate redundant content."

**Result**: Single cohesive responses with no redundancy

## Files Modified

**Bug Fixes:**
1. `/app/api/corpus/delete/route.ts` - Reject button fix (File Search Store deletion)
2. `/lib/sanitize.ts` - Follow-up query fix (removed 1000-char limit on history)

**Two-Tab Architecture:**
3. `/app/api/summary/route.ts` - Reverted to corpus-only with strict citations, removed Mode/Length parameters
4. `/app/api/web-search/route.ts` - NEW: Google Search endpoint (minimal system instruction)
5. `/components/agents/browse-query-agent.tsx` - Simplified UI (removed Mode/Length/Custom)
6. `/components/agents/web-search-agent.tsx` - NEW: Clean query input UI for web search
7. `/app/page.tsx` - Updated to 7 tabs (added "Search Web")

## Git Commits

1. `cfb4ceb` - BUGFIX: Fix TypeScript error in summary-agent
2. `6c2c3fb` - BUGFIX: Query Corpus follow-ups + Upload CSP violations
3. `3444a63` - BUGFIX: Fix Reject Button + Follow-up Query Issues
4. `319b25d` - FEATURE: Add Google Search Grounding (reverted due to API limitation)
5. `6459715` - FEATURE: Sequential Dual-Query System (Query 2 had issue)
6. `4bec4a5` - FEATURE: Separate Corpus and Web Search Tabs
7. `a123ef8` - BUGFIX: Prevent duplicate lists in corpus and web search
8. `88e18a2` - CRITICAL: Enforce strict corpus-only citations
9. `daa508d` - SIMPLIFY: Remove Mode/Length/Custom Instructions UI
10. `c481264` - DOCS: Update documentation for Session 21 completion

## Results

**Query Corpus Test** (PD context question):
- 10 specific facts with FULL citations
- Example: `[cite: History2012, 特殊鋼の研究・開発と鍛造技術の研究, p.1]`
- Specific dates: 1934, 1950s, 1960s, 1970s
- Specific names: Kiichiro Toyoda, Toyopet Crown, Toyoda Koki
- Specific tools: TOGO CAD, Shusa system
- Single cohesive list (no duplicates)

**Search Web Test** (same question):
- Generic principles: Chief Engineer, Set-Based Design, Knowledge Management
- No specific dates or implementations
- Abstract concepts (Lean 101 level)
- No primary source citations
- Sources: lean.org, productdevelopmentinstitute.com

**Impact**: System now perfectly demonstrates the knowledge gap between:
- **Corpus**: Hidden authoritative facts from primary sources
- **Web**: Surface-level generic knowledge (what everyone thinks they know)

## Next Session Priorities

1. **Build Editorial Agent (OPTIONAL)** - Final polish for structure, grammar, clarity
   - Simpler than Analyze (no corpus interaction)
   - Decision point: Assess if needed vs. external LLMs (Claude, ChatGPT)
   - Estimated time: 1-2 hours

2. **Continue Corpus Expansion** - Target: 300+ documents
   - Current: 240 documents (204 classified by quality tier)
   - Focus: PD, PE, TPS primary sources
   - Promote Tier 2 PDFs to Tier 1 (ex-Toyota authors)

3. **Optional Enhancements**
   - Corpus statistics dashboard
   - Bulk metadata editing
   - Export corpus to JSON/CSV

## User Feedback

- **Key Insight**: "The google search of the internet will always return the perceived common answer but not the best facts and details."
- **Final Test Results**: "This last result proved what I feared" → System demonstrates hidden knowledge perfectly
- Satisfied with two-tab architecture showing knowledge gap
- Prefers full control through detailed prompts (no UI constraints)

## Technical Notes

- Google Gemini API does NOT support File Search + Google Search together (API limitation)
- Sequential approach executed but revealed Query 2 returns generic knowledge
- Final solution: Separate tabs to highlight knowledge gap
- Strict citation enforcement prevents model from using training data
- Current corpus: 240 documents, all searchable via File Search Store
- System now working exactly as intended ✅
