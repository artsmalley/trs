# Session 24 - Supabase Phase 1: Infrastructure Setup (2025-01-20)

## Session Overview

**Focus**: Supabase migration Phase 1 - Database infrastructure setup
**Duration**: ~45 minutes
**Status**: COMPLETE âœ…

## What We Accomplished

### 1. Migration Planning & Research (Pre-Session)
- Cross-verified migration approach with both OpenAI and Gemini
- Confirmed gemini-embedding-001 (1536d) as optimal choice
- Validated Matryoshka embedding approach (1536 = 98-99% of 3072 performance)
- Created comprehensive migration plan: `supabase-migration-plan.md`

### 2. Supabase Project Creation
- Created new Supabase project: "TRS"
- Retrieved all credentials (URL, anon key, service role key)
- Added to `.env.local`:
  - `NEXT_PUBLIC_SUPABASE_URL`
  - `NEXT_PUBLIC_SUPABASE_ANON_KEY`
  - `SUPABASE_SERVICE_ROLE_KEY`

### 3. Database Schema Deployment

#### pgvector Extension
```sql
CREATE EXTENSION IF NOT EXISTS vector WITH SCHEMA extensions;
```
- Installed in `extensions` schema (best practice)
- Supports 1536-dimensional vectors

#### Documents Table
```sql
CREATE TABLE documents (
  id UUID PRIMARY KEY,
  title TEXT NOT NULL,
  citation_key TEXT NOT NULL UNIQUE,  -- e.g., "Yoshino1985"
  authors TEXT[],
  year INTEGER,
  track TEXT,
  summary TEXT,
  keywords TEXT[],
  quality_tier INTEGER CHECK (quality_tier BETWEEN 1 AND 4),
  tier_label TEXT,
  blob_url TEXT NOT NULL,
  file_name TEXT NOT NULL,
  file_size_bytes BIGINT,
  source_url TEXT,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);
```

#### Chunks Table
```sql
CREATE TABLE chunks (
  id UUID PRIMARY KEY,
  document_id UUID NOT NULL REFERENCES documents(id) ON DELETE CASCADE,
  text TEXT NOT NULL,
  page_number INTEGER,
  chunk_index INTEGER,
  embedding extensions.vector(1536) NOT NULL,  -- 1536-dimensional vectors
  token_count INTEGER,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- HNSW index for fast similarity search
CREATE INDEX idx_chunks_embedding ON chunks
USING hnsw (embedding vector_cosine_ops);
```

**Key Feature**: `document_id` is a **foreign key** â†’ Direct SQL JOIN for citations!

#### Search Function
```sql
CREATE OR REPLACE FUNCTION search_chunks(
  query_embedding extensions.vector(1536),
  match_threshold FLOAT DEFAULT 0.7,
  match_count INT DEFAULT 10,
  filter_quality_tiers INT[] DEFAULT NULL
)
RETURNS TABLE (
  chunk_id UUID,
  document_id UUID,
  citation_key TEXT,    -- â† Direct from JOIN!
  title TEXT,           -- â† Direct from JOIN!
  page_number INTEGER,
  text TEXT,
  similarity FLOAT
)
```

**Magic**: SQL JOIN automatically provides `citation_key` and `title` - no string parsing needed!

### 4. Security Hardening

#### Row Level Security (RLS)
```sql
ALTER TABLE documents ENABLE ROW LEVEL SECURITY;
ALTER TABLE chunks ENABLE ROW LEVEL SECURITY;
```

**Result**:
- Public access (anon key) blocked
- Backend access (service_role key) bypasses RLS
- Perfect for single-user backend app

#### Function Security
```sql
-- Added to search_chunks function
SECURITY DEFINER
SET search_path = public, extensions
```

**Final Security Status**:
- âœ… 0 Errors
- âœ… 0 Warnings
- â„¹ï¸ 2 Informational suggestions (intentional - RLS with no policies blocks public access)

### 5. TRS Integration

#### NPM Package
```bash
npm install @supabase/supabase-js
```

#### Supabase Client (`lib/supabase-client.ts`)
```typescript
import { createClient } from '@supabase/supabase-js';

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!;
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY!;

export const supabase = createClient(supabaseUrl, supabaseServiceKey, {
  auth: {
    autoRefreshToken: false,
    persistSession: false
  }
});
```

#### Test Script (`test-supabase-connection.js`)
```javascript
// Tests:
// 1. Insert test document
// 2. Insert test chunk with 1536-dimensional vector
// 3. Query with SQL JOIN
// 4. Test search_chunks function
// 5. Clean up (CASCADE delete)
```

**Test Results**: All 5 tests passed âœ…

### 6. Citation System Architecture

**Old System (File Search Store - Fragile)**:
```typescript
// Parse chunk title and hope for a match
const normalizedTitle = chunkTitle.replace(/-/g, '').replace(/\./g, '');
const matchedDoc = approvedDocs.find(doc =>
  doc.fileId && doc.fileId.includes(normalizedTitle)  // ðŸ¤ž Hope this works!
);
```

**New System (Supabase - Rock Solid)**:
```typescript
// Direct SQL JOIN - citation_key is already there!
const results = await supabase.rpc('search_chunks', { query_embedding });
const citation = {
  key: results[0].citation_key,    // âœ… From JOIN
  title: results[0].title,         // âœ… From JOIN
  page: results[0].page_number     // âœ… From chunk
};
```

**Improvement**:
- Old: "Hope the string parsing finds a match" ðŸ¤ž
- New: "Database guarantees the relationship exists" âœ…
- **100% reliable citations** via foreign key constraints!

---

## Technical Decisions

### Embedding Model: gemini-embedding-001
- **Dimensions**: 1536 (not 768 or 3072)
- **Rationale**: Matryoshka embeddings - 1536 retains 98-99% of semantic information
- **Performance**: Better than 768 for technical content, more efficient than 3072
- **Multilingual**: SOTA for English + Japanese (68.3 MTEB Multilingual)

### Architecture: Parallel Systems
- **Keep File Search Store** (241 documents, working)
- **Add Supabase** (for testing/comparison)
- **UI toggles** (choose backend for upload/query)
- **User uploads 20-40 docs** to Supabase for A/B testing

### Security Best Practices
- âœ… pgvector in `extensions` schema (not `public`)
- âœ… RLS enabled on all tables
- âœ… Function search_path secured
- âœ… Service role key for backend (bypasses RLS)
- âœ… Anon key blocked (RLS with no policies)

---

## Files Created/Modified

### Created
1. `lib/supabase-client.ts` - Supabase connection client
2. `test-supabase-connection.js` - Connection test script
3. `supabase-migration-plan.md` - Comprehensive 4-phase migration plan
4. `docs/progress/2025-01-20-Session24.md` - This file

### Modified
1. `.env.local` - Added 3 Supabase credentials
2. `CLAUDE.md` - Updated migration status, environment setup
3. `Next_steps.md` - Phase 1 complete, Phase 2 next priority
4. `package.json` - Added @supabase/supabase-js dependency

---

## Database Schema Summary

### Tables
- **documents**: Metadata + citation keys + quality tiers
- **chunks**: Text + 1536d vectors + page numbers + foreign key

### Indexes
- Citation key (unique)
- Track, quality tier (filtering)
- Document ID (foreign key)
- Page number (citation extraction)
- **HNSW vector index** (fast similarity search)

### Functions
- **search_chunks()**: Semantic similarity search with SQL JOIN

### Extensions
- **vector**: pgvector for vector similarity (in `extensions` schema)

---

## Testing Results

### Connection Test
```bash
node test-supabase-connection.js
```

**Results**:
```
âœ… Document created with ID: 34e8047e-4c31-4ec8-8900-da6fc578a46d
âœ… Chunk created with ID: 0b9666a3-bca5-41b0-8e59-90e8a5b283a0
âœ… Query successful: Found chunk for document "Test2025"
âœ… Search function working: Found 1 result(s)
   Similarity score: 1.0000
âœ… Test data deleted (CASCADE removes chunk too)

âœ… All tests passed! Supabase is ready for Phase 2.
```

### Security Audit
- Errors: 0 âœ…
- Warnings: 0 âœ…
- Suggestions: 2 (informational, intentional)

---

## Key Learnings

### 1. Foreign Keys = Guaranteed Citations
The foreign key constraint `chunks.document_id â†’ documents.id` makes it **mathematically impossible** for a chunk to exist without a valid document. This eliminates the fragile string parsing of the File Search Store approach.

### 2. Matryoshka Embeddings
Gemini's MRL training means 1536 dimensions capture 98-99% of semantic information, making 3072 dimensions unnecessary for most use cases. Storage efficiency with minimal quality loss.

### 3. RLS Without Policies
For backend-only apps using service_role key:
- Enable RLS (blocks public access)
- Don't create policies (service_role bypasses RLS anyway)
- Result: Secure by default, zero configuration

### 4. Extension Schema Organization
Installing extensions in `extensions` schema (not `public`) is a Supabase best practice. Use fully-qualified names: `extensions.vector(1536)`.

### 5. HNSW Indexing
pgvector's HNSW (Hierarchical Navigable Small World) index provides fast approximate nearest neighbor search. Essential for sub-second query times on large vector datasets.

---

## What's Next: Phase 2

### Backend API Integration (2-3 hours)

**Create RAG Functions** (`lib/supabase-rag.ts`):
- Text chunking (500 tokens, 50 overlap)
- Gemini embedding generation (1536d)
- Document storage in Supabase
- Semantic search queries
- Citation extraction (trivial with SQL JOIN!)

**Dual-Path Upload APIs**:
- `/api/process-blob` - Add `backend` parameter
- `/api/process-url` - Add `backend` parameter
- If `backend === 'supabase'` â†’ chunk + embed + store in Supabase
- If `backend === 'file_search'` â†’ current File Search path (unchanged)

**Dual-Path Query API**:
- `/api/summary` - Add `backend` parameter
- If `backend === 'supabase'` â†’ query Supabase, use SQL JOIN for citations
- If `backend === 'file_search'` â†’ current File Search (unchanged)

**Deliverable**: Upload and query working on both backends

---

## Comparison: File Search vs Supabase

| Aspect | File Search (Current) | Supabase (New) |
|--------|----------------------|----------------|
| **Setup** | Managed service | Self-managed schema |
| **Storage** | Opaque black box | Transparent PostgreSQL |
| **Citations** | Fragile fileId string matching | Direct SQL JOIN (guaranteed) |
| **Debugging** | Limited visibility | Full SQL access |
| **Control** | None | Complete |
| **Chunking** | Automatic (no control) | Custom (500 tokens, 50 overlap) |
| **Embeddings** | Google internal model | gemini-embedding-001 (explicit) |
| **Dimensions** | Unknown | 1536 (configurable) |
| **Cost** | Free tier | $10/month |

---

## Status Summary

### Phase 1: Infrastructure Setup âœ… COMPLETE
- [x] Supabase project created
- [x] Database schema deployed
- [x] Security hardened
- [x] Connection tested
- [x] TRS integration complete

### Phase 2: Backend API Integration (Next)
- [ ] Create RAG functions
- [ ] Update upload APIs (dual-path)
- [ ] Update query API (dual-path)
- [ ] Test end-to-end

### Phase 3: UI Toggles (Later)
- [ ] Upload Agent backend selector
- [ ] Query Corpus backend selector
- [ ] Browse Agent backend indicators

### Phase 4: User Testing (Later)
- [ ] Upload 20-40 test documents
- [ ] Compare query quality
- [ ] Make final decision

---

## Cost Impact

**One-time**: ~$0.30 (embedding generation for test uploads)
**Monthly**: +$10/month Supabase project
**Total monthly**: $65 ($55 current + $10 Supabase)
**Still saving**: $20/month vs. pre-cleanup $85/month

---

## Final Notes

**Time to complete Phase 1**: ~45 minutes (faster than estimated 1-2 hours)

**Why so fast**:
- Clear migration plan (`supabase-migration-plan.md`)
- Well-researched decisions (OpenAI + Gemini cross-verification)
- No data migration needed (manual upload approach)
- Clean database design (followed best practices)

**Key success factors**:
1. Pre-planning paid off (detailed migration plan)
2. Security-first approach (fixed warnings immediately)
3. Testing throughout (caught issues early)
4. Documentation-driven (clear next steps)

**User feedback**: "This plan is excellent. It is technically sound, low-risk, and directly addresses the 'fragility' of your current system while keeping the cost negligible."

---

**Phase 1 Status**: âœ… COMPLETE - Ready for Phase 2!
